createdAt: "2019-01-15T08:11:37.311Z"
updatedAt: "2021-01-15T06:35:02.580Z"
type: "MARKDOWN_NOTE"
folder: "1e8e7087e48b4c193327"
title: "matrix basics"
tags: []
content: '''
  ## matrix basics
  
  *Jordan Canonical Form(JCF):*
  > for all $A\\in C^{n\\times n}$ with eigen values $\\lambda_1, ..., \\lambda_n\\in C$(not necessarily distinct), there exists $X\\in C^{n\\times n}_ n$ such that: 
  > $$X^{-1}AX = J = diag (J_1, ..., J_q)$$
  
  $AC^T =|A| \\ \\mathbf I$, $C$为伴随矩阵
  
  条件数:
  $$ cond(A) = ||A|| \\ ||A^{-1}|| $$
  方阵$A$奇异即条件数为$\\infty$. 条件数描述了其对应线性系统的稳定性或敏感程度,
  
  ##### 范数
  假设$V$是域$\\mathbf F$上的向量空间, $V$的**半范数**是一个函数$p: V \\rightarrow \\mathbb R; x \\rightarrow p(x)$, 满足:
  $\\forall a \\in \\mathbf F, \\forall u, v \\in V$,
  1. 正定: $p(v) \\ge 0$
  2. 齐次: $p(av)=|a|\\ p(v)$
  3. 三角不等式: $p(u+v) \\le p(u)+p(v)$
  
  **范数**则加上一个额外性质: $p(v)=0 \\Leftrightarrow v=\\mathbf 0$
  **矩阵范数**还规定满足相容性: $||AB|| \\le ||A||\\ ||B||$, 引入相容性是为了保持矩阵作为线性算子的特征
  
  * F范数
  
  $$ \\lVert A \\rVert _F = \\sqrt{\\sum_{i=1}^m \\sum_{j=1}^n \\lvert a_{ij} \\rvert ^2} = \\sqrt {tr(A^TA)} $$
  
  * p范数
  
  $$ ||A||_p = \\max_{||x||_p \\ne 0} \\frac {||Ax||_p}{||x||_p}=
  \\max_{||x||_p=1}||Ax||_p $$
  $$||A||_1 = \\max_{j\\in n} \\sum_{i=1}^m|a_{ij}|$$
  $$||A||_{\\infty} = \\max_{i\\in m} \\sum_{j=1}^n|a_{ij}|$$
  $$||A||_2 = \\lambda_{max}^{\\frac 12}(A^TA)= \\lambda_{max}^{\\frac 12}(AA^T)
  =\\sigma_1(A) $$
  
  **正定**:
  
  实对称矩阵$A_{n\\times n}$:
  正定 $\\iff$ 合同于单位矩阵 or 特征值大于0 or $X^TAX$的正惯性指数$=n$ or 顺序主子式都大于0
  半正定 $\\iff$ 合同于分块矩阵$(E_r, 0; 0, 0)$特征值大于0且至少有一个=0 or $X^TAX$的正惯性指数$p< n$
  
  **矩阵分解**:
  - **对角化:** 
  $S^{-1}AS = \\Lambda$, $S$由特征向量组成, 需要所有特征向量相互独立, 即特征值互不相同
  
  * **LU分解:**
  $A=LU$, 对应于高斯消元由上至下消去获得*行梯阵式*, 求解线性方程组时即由下至上进行(消元获得)
  
  * **QR分解:**
  将**列满秩**矩阵分解为$A=QR$, 获得正交阵$Q: Q^TQ=I$(将$A$的列不断投影获得一组正交基即得到$Q$)
  
  * **Cholesky分解:**
  奖对称正定阵分解为$A=LDL^T$, 对实对称矩阵存在特征分解$A=Q\\Lambda Q^T$
  
  对于对阵矩阵来说:
  1) 有实特征值和正交的特征向量
  2) 对角化: $A = Q\\Lambda Q^T, Q$为正交阵
  3) 即使存在重复的特征值也可以对角化
  4) 特征值符号与pivots相同
  
  **特征值**:
  
  $$ \\left \\{ \\begin{matrix} \\sum_i \\lambda_i = tr(A) \\\\ \\prod _i \\lambda_i = |A|
  \\end{matrix} \\right.$$
  
  $$ since \\quad |A-\\lambda I| = \\prod_i (\\lambda_i-\\lambda)=0 $$
  
  简单证明:令特征值构成$X = [x_i]$, 有$AX = [Ax_i]\\Rightarrow |A||X| = \\prod \\lambda_i|X|$
  
  对称阵不同特征值对应的特征向量垂直:
  
  $$ \\lambda x^T y = x^T A^Ty = x^T \\mu y \\Rightarrow (\\lambda - \\mu)x^T y = 0$$
  
  矩阵$A$正定当且仅当其所有特征值为正
  
  对任意特征向量$r$: $0 < r^TAr = r^T\\lambda r = \\lambda \\ ||r||^2 \\Rightarrow \\lambda > 0$
  
  对任意$x$: 记$x = \\sum \\alpha_i r_i$, 则$x^TAx = x^T \\sum \\lambda_i \\alpha_i r_i \\ge (\\min \\lambda_i)\\ ||x||^2>0$
  
  **伪逆**:
  
  对$A: \\mathcal X \\to \\mathcal Y$, 定义$T: \\mathcal N(A)^\\perp  \\to \\mathcal R(A)$为:
  $$ Tx = Ax, \\forall x \\in \\mathcal N(A)^\\perp $$
  由此定义伪逆$A^+: \\mathcal Y \\to \\mathcal X$
  $$ A^+y = T^{-1}y_1$$
  其中$y_1$为$y \\in R^n$在$\\mathcal{R}(A)$中的分量(即忽视正交补中的分量)
  
  常规svd分解求伪逆:
  $$A^+ = V\\Sigma^+ U^T, \\quad
  \\Sigma^+ = [\\sigma^{-1}, ..., 0, ...] $$
  qr分解求伪逆:
  $$A^+ = R^{-1}Q^T$$
  
  剔除一个空间分量:
  $$\\hat R = R-CC^+R$$
  
  **矩阵最小二乘**:
  $$AX = B; \\quad A \\in R^{m \\times n}, B \\in R^{m\\times k}$$
  通解:
  $$X = A^+B + (I-A^+ A)Y, \\quad \\forall \\ Y\\in R^{n\\times k}$$
  其中$A^+B$为使得$Tr X^TX$取最小值
  
  SVD求解：
  $$AX=0$$
  $$ |AX| = |U\\Sigma V^TX| = |\\Sigma (V^TX)| \\Rightarrow V^TX = [0,0,...,1] \\Rightarrow X = v_m $$
  
  2范数$k$秩近似:
  $$ \\min_{M\\in R_k^{m\\times n}} ||A-M||_2 \\quad \\rightarrow \\quad M= \\sum_{i=1}^k \\sigma_i u_i v_i^T $$
  特别地，对$n$阶方阵计算的$k-1$阶近似为其最近的奇异阵
  
  **几个常用公式**:
  
  $$ (A+BDC)^{-1} = A^{-1}-A^{-1}B(D^{-1}+CA^{-1}B)^{-1}CA^{-1} $$
  $$ (A^{-1} + B^{-1})^{-1} = A- A(A+B)^{-1}A = B- B(A+B)^{-1}B $$
  $$ \\begin{bmatrix} A& B \\\\ 0& D \\end{bmatrix}^{-1} = 
  \\begin{bmatrix} A^{-1}& -A^{-1}BD^{-1} \\\\ 0& D^{-1} \\end{bmatrix} $$
  $$ \\begin{bmatrix} A& 0 \\\\ C& D \\end{bmatrix}^{-1} = 
  \\begin{bmatrix} A^{-1}& 0 \\\\ -D^{-1}CA^{-1}& D^{-1} \\end{bmatrix} $$
  $$\\det(I-AB) = \\det(I-BA)$$
  
  $$ x^Ty = tr(yx^T)\\to x^TAx = tr(xx^TA)$$
  
  #### 反对称
  $$a^\\times b = -b^\\times a $$
  $$aa^T-(a^\\times)^2 = I$$
  $$ (Qa)^\\times = Qa^\\times Q^T $$
  $$ \\phi_1^\\times \\phi_2^\\times - \\phi_2^\\times \\phi_1^\\times = (\\phi_1^\\times \\phi_2)^\\times $$
  
  > a linear transformation $P$ is a projection *if and only if* it is **idempotent(幂等)**, i.e. $P^2=P$. also, $P$ is a projection *if and only if* $I-P$ is a projection. in fact: $P_{\\mathcal Y, \\mathcal X}=I-P_{\\mathcal X, \\mathcal Y}$. 
  
  $$ <x, Ay>_Q = <Bx, y>_R \\quad \\rightarrow \\quad B = R^{-1}A^TQ$$
  
  > let $A \\in R_r^{m\\times n}$ with SVD: $A=U\\Sigma V^T= \\sum_{i=1}^r 
  \\sigma_i u_i v_i^T$, then a best rank k approximaition to $A$ for $1\\le k\\le r$, i.e., a solution to $\\min_{M\\in R_k^{m\\times n}} ||A-M||_2$, is given by 
  $M_k = \\sum_{i=1}^k \\sigma_i u_i v_i^T$.
  
  > if $\\lambda$ is a root ot *mutiplicity* $m$ of $\\pi(\\lambda)$, we say that $\\lambda$ is an eigenvalue of $A$ of **algebraic multiplicity** $m$. the **geometric multiplicity** of $\\lambda$ is the number of associated independent eigenvectors $=n- rank(A-\\lambda I) = \\dim \\mathcal{N}(A-\\lambda I)$
  
  > if $f$ is a analytic function, then the eigenvalues of $f(A)$ are $f(\\lambda)$, buf $f(A)$ does not necessarily have all the same eigenvectors, unless, say, $A$ is **diagonalizable**.
  
  > a complex square matrix $A$ is **normal** if: $A^TA = AA^T$，也就是说对称、反对称、正交
  
  #### kronnecker & vectorization
  $$A\\otimes B =\\{a_{ij}B\\}$$
  $$(aA)\\otimes(bB) = ab(A\\otimes B) $$
  $$(A+B)\\otimes C = (A\\otimes C)+ (B\\otimes C)$$
  
  $$(A\\otimes B)(C\\otimes D) = AC\\otimes BD$$
  $$|A_{n\\times n}\\otimes B_{m\\times m}| = |A|^m|B|^n$$
  $$(A\\otimes B)^T = A^T\\otimes B^T$$
  $$(A\\otimes B)^{-1} = A^{-1}\\otimes B^{-1}$$
  $$A\\oplus B = I_m\\otimes A+ B\\otimes I_n$$
  
  $$vec(XY) =  (I_k \\otimes X)vec(Y) = (Y^T \\otimes I_k) \\ vec(X) $$
  $$vec(AYC) = (C^T \\otimes A) \\ vec(Y) $$
  
'''
isStarred: false
isTrashed: false
linesHighlighted: [
  6
]
